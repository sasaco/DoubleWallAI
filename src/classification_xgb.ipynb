{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類モデル（XGBoost）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## csvの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データの読み込み\n",
    "## xgboostは型にcategoryを使えないため，one-hot-encordingが必要\n",
    "data_folder = input(\"データファイルのあるフォルダまでのパス\")\n",
    "data_folder = data_folder.rstrip()\n",
    "data_folder = data_folder.replace(\"\\\\\", \"/\") + \"/\"\n",
    "\n",
    "file = data_folder + \"input20001_30000_input+error_dummy.csv\"\n",
    "\n",
    "df = pd.read_csv(file,  encoding=\"shift-jis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#目的変数\n",
    "pur = \"安全率エラー判定\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font='Yu Gothic',rc = {'figure.figsize':(200,200)})\n",
    "sns.heatmap(df.corr(),square=True, vmax=1, vmin=-1, center=0,cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font='Yu Gothic',rc = {'figure.figsize':(100,100)})\n",
    "dff = df.copy()\n",
    "# dff = dff.drop([\"評価_状態\"],axis = 1)\n",
    "sns.heatmap(dff.corr()[[pur]].sort_values(by=pur, ascending=False)[1:],cmap='coolwarm', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの分割\n",
    "# 全体の20%をテストデータに設定\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.2, random_state = 9, stratify = df.loc[:,pur])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### アンダーサンプリングとクロスバリデーション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified K Foldでデータを分割\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# 目的変数と説明変数に分ける\n",
    "X = train.drop([pur], axis = 1) # 予測対象以外を説明変数に設定\n",
    "y = train.loc[:,pur]\n",
    "\n",
    "#アンダーサンプリング　3:1\n",
    "positive_count_train = y.value_counts()[1]\n",
    "strategy = {0.0:positive_count_train*3, 1.0:positive_count_train}\n",
    "rus=RandomUnderSampler(random_state=9, sampling_strategy = strategy)\n",
    "X, y = rus.fit_resample(X, y)\n",
    "train = pd.concat([y,X],axis=1)\n",
    "\n",
    "print(len(X))\n",
    "\n",
    "# Trainデータの層状k分割\n",
    "# ライブラリのインポート\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0) # データを5分割する\n",
    "kf = fold.split(X, y)\n",
    "kf_cv = list(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (idx_train, idx_val) in enumerate(kf_cv):\n",
    "    print(f'fold {i}')\n",
    "    print(idx_train)\n",
    "    print(idx_val)\n",
    "    print('=='*30)\n",
    "    print(len(idx_train), len(idx_val)) #5分割しているのでデータ数が1:4になるか確認する\n",
    "    print('=='*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost.callback import early_stop\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics # 正解率を出すためのライブラリ\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV,StratifiedKFold,cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ハイパーパラメータチューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "def objective(trial,df_X,df_y):\n",
    "    \n",
    "    params ={\n",
    "    'max_depth':trial.suggest_int(\"max_depth\",3,10),\n",
    "    'min_child_weight':trial.suggest_int('min_child_weight',1,5),\n",
    "    'gamma':trial.suggest_uniform('gamma',0,5),\n",
    "    'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
    "    'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1),\n",
    "    'learning_rate':trial.suggest_uniform('learning_rate',0,1)}\n",
    "\n",
    "    model = xgb.XGBClassifier(n_estimators=100,\n",
    "                            verbosity=0,\n",
    "                            n_jobs=-1,\n",
    "                            random_state=0,\n",
    "                            **params)\n",
    "\n",
    "    #交差検証\n",
    "    scores = cross_val_score(model, df_X, df_y,cv=5,scoring=\"accuracy\")\n",
    "    score_mean = np.mean(scores)\n",
    "\n",
    "    return score_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optuna.create_study()でoptuna.studyインスタンスを作る。\n",
    "study = optuna.create_study(direction = 'maximize')\n",
    "\n",
    "#studyインスタンスのoptimize()に作った関数を渡して最適化する。\n",
    "study.optimize(lambda trial: objective(trial,X,y),n_trials=200, timeout=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#スコアを見る\n",
    "print(study.best_params)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'objective': 'binary:logistic',  # 2値分類問題\n",
    "    'eval_metric': 'logloss',       # 学習用の指標\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params['max_depth'] = study.best_params['max_depth']\n",
    "xgb_params['min_child_weight'] = study.best_params['min_child_weight']\n",
    "xgb_params['gamma'] = study.best_params['gamma']\n",
    "xgb_params['subsample'] = study.best_params['subsample']\n",
    "xgb_params['colsample_bytree'] = study.best_params['colsample_bytree']\n",
    "xgb_params['learning_rate'] = study.best_params['learning_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習開始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import average_precision_score\n",
    "import shap\n",
    "import japanize_matplotlib\n",
    "\n",
    "def fit_xgb(X, y, cv, params: dict=None):\n",
    "    \n",
    "    models = []\n",
    "    acc = []\n",
    "    oof_plob = np.zeros(len(X))\n",
    "    oof_classfication = np.zeros(len(X))\n",
    "\n",
    "    if params is None:\n",
    "        params = {}\n",
    "\n",
    "    threshold_all = []\n",
    "    for i, (idx_train, idx_val) in enumerate(kf_cv):\n",
    "        X_train, y_train = X.iloc[idx_train], y.iloc[idx_train] # 学習用の説明変数と目的変数の呼び出し\n",
    "        X_val, y_val = X.iloc[idx_val], y.iloc[idx_val]\n",
    "\n",
    "        clf = xgb.XGBClassifier(**params)\n",
    "        model = clf.fit(X_train, y_train,\n",
    "                        eval_set=[(X_val, y_val)],  \n",
    "                        early_stopping_rounds=20,\n",
    "                        verbose = 2)\n",
    "\n",
    "        pred_prob = model.predict_proba(X_val)[:,1] # どのクラスに分類されるのかの確率を算出\n",
    "        print(pred_prob)\n",
    "\n",
    "        explainer = shap.TreeExplainer(model = model,data=X_train,feature_perturbation=\"interventional\")\n",
    "        shap_values = explainer(X_train)\n",
    "        shap.plots.bar(shap_values=shap_values,max_display=10)\n",
    "        shap.plots.beeswarm(shap_values,max_display=10)\n",
    "       \n",
    "        def accuracy(y_val, pred_prob, threshold):\n",
    "            pred = [1 if prob >= threshold else 0 for prob in pred_prob]\n",
    "            score = metrics.f1_score(y_val, pred)\n",
    "            return score\n",
    "        \n",
    "        def objective(trial):\n",
    "            threshold = trial.suggest_float('threshold', 0.0, 1.0) # 0~1.0で探索\n",
    "            ret = accuracy(y_val, pred_prob, threshold)\n",
    "            return ret\n",
    "        \n",
    "        # 閾値の最適化\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=200)\n",
    "\n",
    "        # 閾値の呼び出し\n",
    "        best_threshold = sorted(study.best_params.values())\n",
    "        pred = np.where(pred_prob > best_threshold,1,0)\n",
    "\n",
    "        print(best_threshold)\n",
    "        \n",
    "        oof_plob[idx_val] = pred_prob\n",
    "        print(pred)\n",
    "        \n",
    "        oof_classfication[idx_val] = pred\n",
    "\n",
    "        models.append(model)\n",
    "        threshold_all.append(best_threshold[0])\n",
    "\n",
    "        acc.append(metrics.accuracy_score(y_val, pred))\n",
    "    \n",
    "    print(f'classification_report：{metrics.classification_report(y_val, pred)}')\n",
    "\n",
    "    return oof_plob,oof_classfication, models, threshold_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_plob,oof_classfication, models,threshold_all = fit_xgb(X, y, kf_cv, xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#確率分布\n",
    "sns.distplot(oof_plob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#確率\n",
    "oof_plob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.average(threshold_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テストデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "\n",
    "def inference_xgb(models):\n",
    "    # testデータに対して推論を行う\n",
    "    X_test = test.drop([\"安全率エラー判定\"], axis=1)\n",
    "    y_test = test['安全率エラー判定']\n",
    "\n",
    "    pred_test_prob = np.zeros((len(y_test),len(y.unique()))) # 320×6の2次元配列を作成    \n",
    "\n",
    "    for model in models:\n",
    "        pred_test_prob += model.predict_proba(X_test)/5\n",
    "\n",
    "    # AUC曲線\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from sklearn.metrics import roc_curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, pred_test_prob[:,1] )\n",
    "    plt.plot(fpr, tpr, marker='o')\n",
    "    plt.xlabel('FPR: False positive rate')\n",
    "    plt.ylabel('TPR: True positive rate')\n",
    "    plt.grid()\n",
    "    print(roc_auc_score(y_test, pred_test_prob[:,1] ))\n",
    "\n",
    "    pred_test = (pred_test_prob[:,1]  > (np.average(threshold_all))).astype(int)\n",
    "\n",
    "    #正解率\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print('Accuracy:',accuracy_score(y_test,pred_test_aaa))\n",
    "\n",
    "    cm = confusion_matrix( y_test , pred_test_aaa ) \n",
    "    print(cm)\n",
    "    print(f'Classification Report:{metrics.classification_report(y_test, pred_test)}')\n",
    "\n",
    "    return pred_test_prob,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_prob,X_test,y_test = inference_xgb(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pred_test_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(oof_plob,label=\"検証用oof\")\n",
    "sns.distplot(pred_test_prob[:,1],bins=25,label=\"テスト予測確率\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_prob[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"prob\"] = oof_plob\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"prob\"] = pred_test_prob[:,1]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob = pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全データについて考える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def all_data_xgb(models):\n",
    "    # testデータに対して推論を行う\n",
    "    X_all = df.drop([\"安全率エラー判定\"], axis=1)\n",
    "    y_all = df['安全率エラー判定']\n",
    "\n",
    "    pred_all_prob = np.zeros((len(y_all),len(y_all.unique()))) # 320×6の2次元配列を作成   \n",
    "    print(pred_all_prob.shape) \n",
    "\n",
    "    for model in models:\n",
    "        pred_all_prob += model.predict_proba(X_all)/5\n",
    "        explainer = shap.TreeExplainer(model = model,data=X_all,feature_perturbation=\"interventional\")\n",
    "        shap_values = explainer(X_all)\n",
    "        shap.plots.bar(shap_values=shap_values,max_display=10)\n",
    "        shap.plots.beeswarm(shap_values,max_display=10)\n",
    "\n",
    "    \n",
    "    pred_all = (pred_all_prob[:,1]  > (np.average(threshold_all))).astype(int)\n",
    "    # pred_all = np.where(pred_all_prob[:,1] > 0.5,1,0)\n",
    "\n",
    "    print(pred_all)\n",
    "\n",
    "    df2[\"predicted\"] = pred_all\n",
    "\n",
    "    print(f'ClassificationReport:',metrics.classification_report(y_all, pred_all))\n",
    "\n",
    "    #適合率\n",
    "    from sklearn.metrics import precision_score\n",
    "    print('Precision:', precision_score(y_all, pred_all))\n",
    "\n",
    "    \n",
    "    #AUC曲線\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from sklearn.metrics import roc_curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, pred_test_prob[:,1] )\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('FPR: False positive rate')\n",
    "    plt.ylabel('TPR: True positive rate')\n",
    "    plt.grid()\n",
    "\n",
    "    print(roc_auc_score(y_all, pred_all_prob[:,1] ))\n",
    "\n",
    "    print('Accuracy:',accuracy_score(y_all,pred_all))\n",
    "\n",
    "    cm = confusion_matrix( y_all , pred_all ) \n",
    "    print(cm)     \n",
    "\n",
    "    return pred_all_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "\n",
    "df2 = df.copy()\n",
    "df2[\"prob\"] = all_data_xgb(models)[:,1]\n",
    "df2[\"差分\"] = df2[\"安全率エラー判定\"] - df2[\"predicted\"]\n",
    "\n",
    "print(data_folder)\n",
    "# df2.to_csv(f\"{data_folder}\"+\"220822_akiya500.csv\",encoding='utf_8_sig')\n",
    "# df.to_csv(output_data,encoding='utf_8_sig')\n",
    "print(len(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## エラーかどうかの予測確率毎の実際のエラーデータと正常データ件数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import japanize_matplotlib  # <- これ\n",
    "\n",
    "df2.groupby('安全率エラー判定')['prob'].plot.hist(bins=10, alpha=0.8, legend=True,figsize=[10,10])\n",
    "plt.ylim(0, 2000)                 # (2) y軸の表示範囲\n",
    "plt.title('エラーかどうかの予測確率毎の実際のエラーデータと正常データ件数',fontsize = 14)\n",
    "plt.legend(['正常データ','エラーデータ'],fontsize = 20)\n",
    "plt.ylabel(\"データ数\")\n",
    "plt.xlabel(\"予測確率\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import japanize_matplotlib  # <- これ\n",
    "for i in range(5):\n",
    "    ax = xgb.plot_importance(models[i],importance_type='gain')\n",
    "    fig = ax.figure\n",
    "    print(fig.set_size_inches(4, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5つのモデルで重要度が出てくるので箱ひげ図にします、\n",
    "def plot_importance(model, X):\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    for i, model in enumerate(models):\n",
    "        _df = pd.DataFrame()\n",
    "        _df[\"feature_importance\"] = model.feature_importances_\n",
    "        _df[\"column\"] = X.columns\n",
    "        _df[\"fold\"] = i + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, _df], \n",
    "                                          axis=0, ignore_index=True)\n",
    "        print(feature_importance_df)\n",
    "\n",
    "    order = feature_importance_df.groupby(\"column\").sum()[[\"feature_importance\"]].sort_values(\"feature_importance\", ascending=False).index[:150]\n",
    "    print(feature_importance_df)\n",
    "    fig, ax = plt.subplots(figsize=(20, max(10, len(order) * .25)))\n",
    "    sns.boxenplot(data=feature_importance_df, \n",
    "                  x=\"feature_importance\", \n",
    "                  y=\"column\", \n",
    "                  order=order, \n",
    "                  ax=ax, \n",
    "                  palette=None,  \n",
    "                  orient=\"h\")\n",
    "    ax.tick_params(axis=\"x\")\n",
    "    ax.set_title(\"Feature Importance\")\n",
    "    ax.grid()\n",
    "    fig.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "fig, ax = plot_importance(models, X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "960e4bbdb074eafabe5fc342415b9c24d7ab169a3e269a733677831f0c83ad74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
