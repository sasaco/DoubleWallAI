{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二重矢板の予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "from sklearn import preprocessing\n",
    "import japanize_matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.CSVファイルの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データの読み込み\n",
    "data_folder = input(\"データファイルのあるフォルダまでのパス\")\n",
    "data_folder = data_folder.rstrip()\n",
    "data_folder = data_folder.replace(\"\\\\\", \"/\") + \"/\"\n",
    "\n",
    "file1 = data_folder + \"train_data1.csv\"\n",
    "file2 = data_folder + \"train_labels.csv\"\n",
    "\n",
    "df1 = pd.read_csv(file1,encoding=\"cp932\")\n",
    "df2 = pd.read_csv(file2,encoding=\"cp932\")\n",
    "\n",
    "df = pd.concat([df1,df2],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',30)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ラベルエンコーディング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['矢板型'] = df['矢板型'].apply(str)\n",
    "df['矢板材料'] = df['矢板材料'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',35)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 相関を調べる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目的変数の設定\n",
    "pur = \"遮水効果\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font='Yu Gothic',rc = {'figure.figsize':(200,200)})\n",
    "sns.heatmap(df.corr(),square=True, vmax=1, vmin=-1, center=0,cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font='Yu Gothic',rc = {'figure.figsize':(20,20)})\n",
    "sns.heatmap(df.corr()[[pur]].sort_values(by=pur, ascending=False)[1:],cmap='coolwarm', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの分割\n",
    "# 全体の30%をテストデータに設定\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.2, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交差検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified K Foldでデータを分割\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# 目的変数と説明変数に分ける\n",
    "X = train.drop([pur], axis = 1) # 予測対象以外を説明変数に設定\n",
    "y = train.loc[:,pur]\n",
    "\n",
    "# データの分割\n",
    "# ライブラリのインポート\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "fold = KFold(n_splits=5, shuffle=True, random_state=3) # データを5分割する\n",
    "kf = fold.split(X, y)\n",
    "kf_cv = list(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (idx_train, idx_val) in enumerate(kf_cv):\n",
    "    print(f'fold {i}')\n",
    "    print(idx_train)\n",
    "    print(idx_val)\n",
    "    print('=='*30)\n",
    "    print(len(idx_train), len(idx_val)) #5分割しているのでデータ数が1:4になるか確認する\n",
    "    print('=='*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost.callback import early_stop\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics # 正解率を出すためのライブラリ\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV,StratifiedKFold,cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ハイパーパラメータチューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "def objective(trial,df_X,df_y):\n",
    "    \n",
    "    params ={\n",
    "    'max_depth':trial.suggest_int(\"max_depth\",1,10),\n",
    "    'min_child_weight':trial.suggest_int('min_child_weight',1,15),\n",
    "    'gamma':trial.suggest_uniform('gamma',0,5),\n",
    "    'subsample':trial.suggest_uniform('subsample',0,1),\n",
    "    'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1),\n",
    "    'reg_alpha':trial.suggest_uniform('subsample',0,1),\n",
    "    'reg_lambda':trial.suggest_uniform('subsample',0,1),\n",
    "    'learning_rate':trial.suggest_uniform('learning_rate',0,1) \n",
    "    }\n",
    "\n",
    "    model = xgb.XGBRegressor(n_estimators=100,\n",
    "                            verbosity=0,\n",
    "                            n_jobs=-1,\n",
    "                            random_state=42,\n",
    "                            **params)\n",
    "\n",
    "    #交差検証\n",
    "    scores = cross_val_score(model, df_X, df_y, scoring='neg_mean_squared_error',cv=5)\n",
    "    rmse = np.sqrt(-scores)\n",
    "    score_mean = np.mean(rmse)\n",
    "\n",
    "    return score_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optuna.create_study()でoptuna.studyインスタンスを作る。\n",
    "study = optuna.create_study()\n",
    "\n",
    "#studyインスタンスのoptimize()に作った関数を渡して最適化する。\n",
    "study.optimize(lambda trial: objective(trial,X,y),n_trials=200, timeout=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#スコアを見る\n",
    "print(study.best_params)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'objective': 'reg:squarederror',  # 回帰問題\n",
    "    'eval_metric': 'rmse',       # 学習用の指標\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params['max_depth'] = study.best_params['max_depth']\n",
    "xgb_params['min_child_weight'] = study.best_params['min_child_weight']\n",
    "xgb_params['gamma'] = study.best_params['gamma']\n",
    "xgb_params['subsample'] = study.best_params['subsample']\n",
    "xgb_params['colsample_bytree'] = study.best_params['colsample_bytree']\n",
    "xgb_params['learning_rate'] = study.best_params['learning_rate']\n",
    "# xgb_params['reg_alpha'] = study.best_params['reg_alpha']\n",
    "# xgb_params['reg_lambda'] = study.best_params['reg_lambda']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習開始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score,mean_absolute_error\n",
    "import shap\n",
    "\n",
    "def fit_xgb(X, y, cv, params: dict=None):\n",
    "    models = []\n",
    "    ma = []\n",
    "    oof = np.zeros(len(X))\n",
    "    # oof_classfication = np.zeros(len(X))\n",
    "\n",
    "    if params is None:\n",
    "        params = {}\n",
    "\n",
    "    threshold_all = []\n",
    "    for i, (idx_train, idx_val) in enumerate(kf_cv):\n",
    "        X_train, y_train = X.iloc[idx_train], y.iloc[idx_train] # 学習用の説明変数と目的変数の呼び出し\n",
    "        X_val, y_val = X.iloc[idx_val], y.iloc[idx_val]\n",
    "\n",
    "        reg = xgb.XGBRegressor(**params)\n",
    "        model = reg.fit(X_train, y_train,\n",
    "                        eval_set=[(X_val, y_val)],  \n",
    "                        early_stopping_rounds=20,\n",
    "                        verbose = 2)\n",
    "\n",
    "        pred = model.predict(X_val)\n",
    "        oof[idx_val] = pred\n",
    "\n",
    "        # acc.append(metrics.accuracy_score(y_val, pred))\n",
    "        models.append(model)\n",
    "        \n",
    "        explainer = shap.TreeExplainer(model = model,data=X_train,feature_perturbation=\"interventional\")\n",
    "        shap_values = explainer(X_train)\n",
    "        shap.plots.bar(shap_values=shap_values,max_display=40)\n",
    "        shap.plots.beeswarm(shap_values,max_display=40)\n",
    "        \n",
    "        print('r2_train:',reg.score(X_train, y_train))\n",
    "        print('r2_val:',reg.score(X_val, y_val))\n",
    "        print('MAE_val: ',mean_absolute_error(y_val, pred))\n",
    "        ma.append(metrics.mean_absolute_error(y_val, pred))\n",
    "\n",
    "    print(f'平均のMAE：{np.mean(ma)}')\n",
    "    return oof, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof,models = fit_xgb(X, y, kf_cv, xgb_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テストデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop([pur], axis=1)\n",
    "y_test = test[pur]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import average_precision_score,mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def inference_xgb(models):\n",
    "    # testデータに対して推論を行う\n",
    "    X_test = test.drop([pur], axis=1)\n",
    "    y_test = test[pur]\n",
    "\n",
    "    pred_test = np.zeros((5,len(y_test))) # 320×6の2次元配列を作成\n",
    "    r2 = []\n",
    "\n",
    "    for i,model in enumerate(models):\n",
    "        pred_test[i] = model.predict(X_test)/5\n",
    "        r2.append(model.score(X_test, y_test))\n",
    "    pred_test = np.sum(pred_test, axis=0) \n",
    "\n",
    "    print('MAE_test: ',mean_absolute_error(y_test, pred_test))\n",
    "    print('r2_test_average:',np.mean(r2))\n",
    "\n",
    "    return pred_test,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test,X_test,y_test = inference_xgb(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全体の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"predict\"] = oof\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"predict\"] = pred_test\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.concat([train,test])\n",
    "df_pred = df_pred.sort_index()\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測結果の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x軸が予測値，y軸が結果\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.scatter(df_pred[\"predict\"],df_pred[pur], alpha = 0.5)\n",
    "plt.plot(np.linspace(0, 6, 6), np.linspace(0, 6, 6), \"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  特徴量重要度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5つのモデルで重要度が出てくるので箱ひげ図にします、\n",
    "def plot_importance(model, X):\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    for i, model in enumerate(models):\n",
    "        _df = pd.DataFrame()\n",
    "        _df[\"feature_importance\"] = model.feature_importances_\n",
    "        _df[\"column\"] = X.columns\n",
    "        _df[\"fold\"] = i + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, _df], \n",
    "                                          axis=0, ignore_index=True)\n",
    "\n",
    "    order = feature_importance_df.groupby(\"column\").sum()[[\"feature_importance\"]].sort_values(\"feature_importance\", ascending=False).index[:50]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, max(6, len(order) * .25)))\n",
    "    sns.boxenplot(data=feature_importance_df, \n",
    "                  x=\"feature_importance\", \n",
    "                  y=\"column\", \n",
    "                  order=order, \n",
    "                  ax=ax, \n",
    "                  palette=None,  \n",
    "                  orient=\"h\")\n",
    "    ax.tick_params(axis=\"x\")\n",
    "    ax.set_title(\"Feature Importance\")\n",
    "    ax.grid()\n",
    "    fig.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "fig, ax = plot_importance(models, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shap値個々の値についてしらべる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_part(val):\n",
    "    X_predict = df_pred.drop([pur,\"predict\"], axis=1)\n",
    "    y_predict = df_pred[pur] \n",
    "\n",
    "    for model in models:\n",
    "        explainer = shap.TreeExplainer(model = model,data=X_predict,feature_perturbation=\"interventional\")\n",
    "        shap_values = explainer(X_predict)\n",
    "        shap.plots.waterfall(shap_values=shap_values[val],max_display=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#引数にはデータの何番目の値の詳細を見たいかをいれる．\n",
    "#モデルごとにwaterfall図が出る．モデルによって異なる．\n",
    "#f(x):モデルの予測値\n",
    "#E[f(x)]:モデル予測値全体の平均\n",
    "shap_part(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "960e4bbdb074eafabe5fc342415b9c24d7ab169a3e269a733677831f0c83ad74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
